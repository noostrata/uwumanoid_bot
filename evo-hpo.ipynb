{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "from ray.air.integrations.wandb import WandbLoggerCallback, setup_wandb\n",
    "\n",
    "# Define the custom network structure\n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, num_classes):\n",
    "        super(CustomNet, self).__init__()\n",
    "        layers = [nn.Linear(input_size, hidden_layers[0]), nn.ReLU()]\n",
    "        for i in range(len(hidden_layers) - 1):\n",
    "            layers += [nn.Linear(hidden_layers[i], hidden_layers[i + 1]), nn.ReLU()]\n",
    "        layers.append(nn.Linear(hidden_layers[-1], num_classes))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Training and evaluation logic\n",
    "def train_model(config):\n",
    "    wandb = setup_wandb(config, project=\"project_name\")\n",
    "    net = CustomNet(config[\"input_size\"], config[\"hidden_layers\"], config[\"num_classes\"])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        inputs = torch.from_numpy(config[\"X_train\"])\n",
    "        labels = torch.from_numpy(config[\"y_train\"])\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        accuracy = evaluate_model(net, config[\"X_test\"], config[\"y_test\"])\n",
    "        wandb.log({\"epoch\": epoch, \"loss\": loss.item(), \"accuracy\": accuracy})\n",
    "        tune.report(accuracy=accuracy)\n",
    "\n",
    "# Mutation function for PBT\n",
    "def mutate_layers(config):\n",
    "    # Example mutation logic - can be adjusted\n",
    "    new_layers = config[\"hidden_layers\"]\n",
    "    if np.random.rand() < 0.5 and len(new_layers) > 1:\n",
    "        new_layers.pop()\n",
    "    else:\n",
    "        new_layers.append(np.random.choice([32, 64, 128]))\n",
    "    return {\"hidden_layers\": new_layers}\n",
    "\n",
    "# PBT Setup\n",
    "scheduler = PopulationBasedTraining(\n",
    "    time_attr=\"training_iteration\",\n",
    "    perturbation_interval=5,\n",
    "    hyperparam_mutations={\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"hidden_layers\": mutate_layers  \n",
    "    }\n",
    ")\n",
    "\n",
    "# Dummy dataset\n",
    "X_train = np.random.rand(1000, 784).astype(np.float32)\n",
    "y_train = np.random.randint(0, 10, 1000).astype(np.long)\n",
    "X_test = np.random.rand(100, 784).astype(np.float32)\n",
    "y_test = np.random.randint(0, 10, 100).astype(np.long)\n",
    "\n",
    "# Run the PBT\n",
    "analysis = tune.run(\n",
    "    train_model,\n",
    "    name=\"pbt_test\",\n",
    "    scheduler=scheduler,\n",
    "    num_samples=4,\n",
    "    config={\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"num_epochs\": 10,\n",
    "        \"input_size\": 784,\n",
    "        \"num_classes\": 2,\n",
    "        \"hidden_layers\": [128],\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test\n",
    "    },\n",
    "    callbacks=[WandbLoggerCallback(project=\"is-project\", api_key=\"a540d30f4375fd2e181491b78a9339e8feaa53e4\")] \n",
    ")\n",
    "\n",
    "best_config = analysis.get_best_config(metric=\"accuracy\", mode=\"max\")\n",
    "print(\"Best config:\", best_config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
